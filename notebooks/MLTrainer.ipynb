{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MLTrainer import MLTrainer\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Classification Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(random_state=42, n_samples=10000, n_features=5, n_classes=3,\n",
    "                          n_informative=2, n_clusters_per_class=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Multiple Models Using MLTrainer\n",
    "\n",
    "Multiple Sklearn models will be trained using either with GridSearchCV or without. The trained models, their parameters and cross validation scores will be stored.\n",
    "\n",
    "Explanations of parameters of methods can be seen in the source code itself. Parameters are fully laid out when calling them in this notebook.\n",
    "\n",
    "Model parameters used for grid search are found in source code, default model parameters are used when grid search is not enabled.\n",
    "\n",
    ".cv_scores attribute contains a Pandas DataFrame containing model names, parameters, mean cross validation scores for each batch and remark. Remark will only have an entry if the model was not able to be trained.\n",
    "\n",
    ".models attribute contains a list of trained model objects\n",
    "\n",
    ".fit method trains multiple models on training set and saves their mean cross validation scores in a Pandas DataFrame\n",
    "\n",
    ".evaluate method generates scores for test set for each model, then saves classification reports, confusion matrices and label probabilities in CSV. Each model will have its own folder in the current directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MLTrainer.models.MLTrainer at 0x7f8b4a218eb8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = MLTrainer(ensemble=True, linear=True, naive_bayes=True, neighbors=True, svm=True, decision_tree=True, seed=100)\n",
    "models.fit(X=X_train, Y=y_train, n_folds=5, scoring=\"accuracy\", n_jobs=-1, gridsearchcv=True, param_grids={}, greater_is_better=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>parameters</th>\n",
       "      <th>mean_cv_accuracy</th>\n",
       "      <th>remarks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adaboost</td>\n",
       "      <td>{'algorithm': 'SAMME', 'base_estimator': None,...</td>\n",
       "      <td>0.917200</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bagging</td>\n",
       "      <td>{'base_estimator': None, 'bootstrap': True, 'b...</td>\n",
       "      <td>0.943733</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>extratrees</td>\n",
       "      <td>{'bootstrap': False, 'ccp_alpha': 0.0, 'class_...</td>\n",
       "      <td>0.942000</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gradientboosting</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...</td>\n",
       "      <td>0.952400</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>randomforest</td>\n",
       "      <td>{'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...</td>\n",
       "      <td>0.946400</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>logreg</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Solver newton-cg supports only 'l2' or 'none' ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bernoulli</td>\n",
       "      <td>{'alpha': 0.1, 'binarize': 0.0, 'class_prior':...</td>\n",
       "      <td>0.904400</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gaussian</td>\n",
       "      <td>{'priors': None, 'var_smoothing': 1e-10}</td>\n",
       "      <td>0.943733</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>multinomial</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Negative values in data passed to MultinomialN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>complement</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Negative values in data passed to ComplementNB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>knn</td>\n",
       "      <td>{'algorithm': 'auto', 'leaf_size': 30, 'metric...</td>\n",
       "      <td>0.944533</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>nu</td>\n",
       "      <td>{'break_ties': False, 'cache_size': 200, 'clas...</td>\n",
       "      <td>0.872933</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>svc</td>\n",
       "      <td>{'C': 0.8, 'break_ties': False, 'cache_size': ...</td>\n",
       "      <td>0.945733</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>decision</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'class_weight': None, 'crit...</td>\n",
       "      <td>0.924933</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>extra</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'class_weight': None, 'crit...</td>\n",
       "      <td>0.927067</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               model                                         parameters  \\\n",
       "0           adaboost  {'algorithm': 'SAMME', 'base_estimator': None,...   \n",
       "1            bagging  {'base_estimator': None, 'bootstrap': True, 'b...   \n",
       "2         extratrees  {'bootstrap': False, 'ccp_alpha': 0.0, 'class_...   \n",
       "3   gradientboosting  {'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...   \n",
       "4       randomforest  {'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...   \n",
       "5             logreg                                               None   \n",
       "6          bernoulli  {'alpha': 0.1, 'binarize': 0.0, 'class_prior':...   \n",
       "7           gaussian           {'priors': None, 'var_smoothing': 1e-10}   \n",
       "8        multinomial                                               None   \n",
       "9         complement                                               None   \n",
       "10               knn  {'algorithm': 'auto', 'leaf_size': 30, 'metric...   \n",
       "11                nu  {'break_ties': False, 'cache_size': 200, 'clas...   \n",
       "12               svc  {'C': 0.8, 'break_ties': False, 'cache_size': ...   \n",
       "13          decision  {'ccp_alpha': 0.0, 'class_weight': None, 'crit...   \n",
       "14             extra  {'ccp_alpha': 0.0, 'class_weight': None, 'crit...   \n",
       "\n",
       "    mean_cv_accuracy                                            remarks  \n",
       "0           0.917200                                                     \n",
       "1           0.943733                                                     \n",
       "2           0.942000                                                     \n",
       "3           0.952400                                                     \n",
       "4           0.946400                                                     \n",
       "5                NaN  Solver newton-cg supports only 'l2' or 'none' ...  \n",
       "6           0.904400                                                     \n",
       "7           0.943733                                                     \n",
       "8                NaN  Negative values in data passed to MultinomialN...  \n",
       "9                NaN  Negative values in data passed to ComplementNB...  \n",
       "10          0.944533                                                     \n",
       "11          0.872933                                                     \n",
       "12          0.945733                                                     \n",
       "13          0.924933                                                     \n",
       "14          0.927067                                                     "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AdaBoostClassifier(algorithm='SAMME', base_estimator=None, learning_rate=0.1,\n",
       "                    n_estimators=50, random_state=None),\n",
       " BaggingClassifier(base_estimator=None, bootstrap=True, bootstrap_features=False,\n",
       "                   max_features=1.0, max_samples=1.0, n_estimators=50,\n",
       "                   n_jobs=None, oob_score=False, random_state=None, verbose=0,\n",
       "                   warm_start=False),\n",
       " ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight='balanced',\n",
       "                      criterion='gini', max_depth=None, max_features='auto',\n",
       "                      max_leaf_nodes=None, max_samples=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=None,\n",
       "                      oob_score=False, random_state=None, verbose=0,\n",
       "                      warm_start=False),\n",
       " GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
       "                            learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "                            max_features='auto', max_leaf_nodes=None,\n",
       "                            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                            min_samples_leaf=1, min_samples_split=2,\n",
       "                            min_weight_fraction_leaf=0.0, n_estimators=50,\n",
       "                            n_iter_no_change=None, presort='deprecated',\n",
       "                            random_state=None, subsample=1.0, tol=0.0001,\n",
       "                            validation_fraction=0.1, verbose=0,\n",
       "                            warm_start=False),\n",
       " RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
       "                        criterion='gini', max_depth=None, max_features='auto',\n",
       "                        max_leaf_nodes=None, max_samples=None,\n",
       "                        min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                        min_samples_leaf=1, min_samples_split=2,\n",
       "                        min_weight_fraction_leaf=0.0, n_estimators=50,\n",
       "                        n_jobs=None, oob_score=False, random_state=None,\n",
       "                        verbose=0, warm_start=False),\n",
       " GridSearchCV(cv=None, error_score=nan,\n",
       "              estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                           fit_intercept=True,\n",
       "                                           intercept_scaling=1, l1_ratio=None,\n",
       "                                           max_iter=100, multi_class='auto',\n",
       "                                           n_jobs=None, penalty='l2',\n",
       "                                           random_state=None, solver='lbfgs',\n",
       "                                           tol=0.0001, verbose=0,\n",
       "                                           warm_start=False),\n",
       "              iid='deprecated', n_jobs=-1,\n",
       "              param_grid={'class_weight': ['balanced'], 'fit_intercept': [True],\n",
       "                          'max_iter': [50], 'multi_class': ['ovr'],\n",
       "                          'penalty': ['l1'], 'solver': ['newton-cg'],\n",
       "                          'tol': [0.0001]},\n",
       "              pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "              scoring=None, verbose=0),\n",
       " BernoulliNB(alpha=0.1, binarize=0.0, class_prior=None, fit_prior=True),\n",
       " GaussianNB(priors=None, var_smoothing=1e-10),\n",
       " GridSearchCV(cv=None, error_score=nan,\n",
       "              estimator=MultinomialNB(alpha=1.0, class_prior=None,\n",
       "                                      fit_prior=True),\n",
       "              iid='deprecated', n_jobs=-1, param_grid={'alpha': [0.1]},\n",
       "              pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "              scoring=None, verbose=0),\n",
       " GridSearchCV(cv=None, error_score=nan,\n",
       "              estimator=ComplementNB(alpha=1.0, class_prior=None, fit_prior=True,\n",
       "                                     norm=False),\n",
       "              iid='deprecated', n_jobs=-1,\n",
       "              param_grid={'alpha': [0.1], 'norm': [True]},\n",
       "              pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "              scoring=None, verbose=0),\n",
       " KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                      metric_params=None, n_jobs=None, n_neighbors=5, p=1,\n",
       "                      weights='uniform'),\n",
       " NuSVC(break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "       decision_function_shape='ovr', degree=1, gamma='auto', kernel='linear',\n",
       "       max_iter=-1, nu=0.1, probability=True, random_state=None, shrinking=False,\n",
       "       tol=0.001, verbose=False),\n",
       " SVC(C=0.8, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "     decision_function_shape='ovr', degree=1, gamma='auto', kernel='linear',\n",
       "     max_iter=-1, probability=True, random_state=None, shrinking=False,\n",
       "     tol=0.001, verbose=False),\n",
       " DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                        max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                        min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                        min_samples_leaf=1, min_samples_split=2,\n",
       "                        min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                        random_state=None, splitter='best'),\n",
       " ExtraTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                     max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                     min_samples_leaf=1, min_samples_split=2,\n",
       "                     min_weight_fraction_leaf=0.0, random_state=None,\n",
       "                     splitter='best')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adaboost': array([2, 0, 0, ..., 1, 1, 1]),\n",
       " 'bagging': array([2, 0, 0, ..., 1, 1, 1]),\n",
       " 'extratrees': array([2, 0, 0, ..., 1, 1, 1]),\n",
       " 'gradientboosting': array([2, 0, 0, ..., 1, 1, 1]),\n",
       " 'randomforest': array([2, 0, 0, ..., 1, 1, 1]),\n",
       " 'logreg': sklearn.exceptions.NotFittedError(\"This LogisticRegression instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\"),\n",
       " 'bernoulli': array([2, 0, 0, ..., 1, 1, 1]),\n",
       " 'gaussian': array([2, 0, 0, ..., 1, 1, 1]),\n",
       " 'multinomial': AttributeError(\"'MultinomialNB' object has no attribute 'feature_log_prob_'\"),\n",
       " 'complement': AttributeError(\"'ComplementNB' object has no attribute 'feature_log_prob_'\"),\n",
       " 'knn': array([2, 0, 0, ..., 1, 1, 1]),\n",
       " 'nu': array([2, 0, 0, ..., 1, 1, 1]),\n",
       " 'svc': array([2, 0, 0, ..., 1, 1, 1]),\n",
       " 'decision': array([2, 0, 0, ..., 1, 1, 1]),\n",
       " 'extra': array([2, 0, 0, ..., 1, 1, 1])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = models.predict(X_test)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adaboost': array([[0.34281552, 0.2800355 , 0.37714899],\n",
       "        [0.37135809, 0.28016314, 0.34847877],\n",
       "        [0.37135809, 0.28016314, 0.34847877],\n",
       "        ...,\n",
       "        [0.31941884, 0.40163403, 0.27894713],\n",
       "        [0.31941884, 0.40163403, 0.27894713],\n",
       "        [0.32305279, 0.39777039, 0.27917682]]),\n",
       " 'bagging': array([[0.  , 0.  , 1.  ],\n",
       "        [0.98, 0.  , 0.02],\n",
       "        [1.  , 0.  , 0.  ],\n",
       "        ...,\n",
       "        [0.  , 1.  , 0.  ],\n",
       "        [0.  , 1.  , 0.  ],\n",
       "        [0.  , 1.  , 0.  ]]),\n",
       " 'extratrees': array([[0.  , 0.  , 1.  ],\n",
       "        [0.94, 0.  , 0.06],\n",
       "        [1.  , 0.  , 0.  ],\n",
       "        ...,\n",
       "        [0.  , 1.  , 0.  ],\n",
       "        [0.  , 1.  , 0.  ],\n",
       "        [0.  , 1.  , 0.  ]]),\n",
       " 'gradientboosting': array([[0.00719011, 0.00333348, 0.98947641],\n",
       "        [0.97954192, 0.00689448, 0.0135636 ],\n",
       "        [0.97954192, 0.00689448, 0.0135636 ],\n",
       "        ...,\n",
       "        [0.00603196, 0.98996448, 0.00400356],\n",
       "        [0.00603196, 0.98996448, 0.00400356],\n",
       "        [0.0078834 , 0.98772158, 0.00439503]]),\n",
       " 'randomforest': array([[0.  , 0.  , 1.  ],\n",
       "        [0.98, 0.  , 0.02],\n",
       "        [1.  , 0.  , 0.  ],\n",
       "        ...,\n",
       "        [0.  , 1.  , 0.  ],\n",
       "        [0.  , 1.  , 0.  ],\n",
       "        [0.  , 1.  , 0.  ]]),\n",
       " 'logreg': sklearn.exceptions.NotFittedError(\"This LogisticRegression instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\"),\n",
       " 'bernoulli': array([[2.05218288e-02, 8.12873510e-08, 9.79478090e-01],\n",
       "        [9.78571755e-01, 7.18038252e-05, 2.13564410e-02],\n",
       "        [9.79285043e-01, 6.50231995e-05, 2.06499335e-02],\n",
       "        ...,\n",
       "        [2.11490311e-02, 9.78841775e-01, 9.19373627e-06],\n",
       "        [2.33196362e-02, 9.76670569e-01, 9.79482474e-06],\n",
       "        [2.11490311e-02, 9.78841775e-01, 9.19373627e-06]]),\n",
       " 'gaussian': array([[2.05852477e-03, 3.41529860e-26, 9.97941475e-01],\n",
       "        [9.99994342e-01, 3.86880253e-24, 5.65765713e-06],\n",
       "        [9.99973654e-01, 1.76814556e-17, 2.63457900e-05],\n",
       "        ...,\n",
       "        [1.46109418e-04, 9.99853891e-01, 1.38961968e-11],\n",
       "        [1.45262651e-04, 9.99854737e-01, 8.23883858e-12],\n",
       "        [2.48348233e-03, 9.97516408e-01, 1.09524866e-07]]),\n",
       " 'multinomial': AttributeError(\"'MultinomialNB' object has no attribute 'feature_log_prob_'\"),\n",
       " 'complement': AttributeError(\"'ComplementNB' object has no attribute 'feature_log_prob_'\"),\n",
       " 'knn': array([[0., 0., 1.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        ...,\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.]]),\n",
       " 'nu': array([[1.41887306e-01, 2.29931838e-04, 8.57882762e-01],\n",
       "        [4.78435458e-01, 5.13907946e-04, 5.21050634e-01],\n",
       "        [5.30459695e-01, 4.18511262e-03, 4.65355193e-01],\n",
       "        ...,\n",
       "        [4.82928654e-06, 9.98792341e-01, 1.20282948e-03],\n",
       "        [3.60461093e-06, 9.98965600e-01, 1.03079580e-03],\n",
       "        [2.15796375e-02, 9.55619621e-01, 2.28007420e-02]]),\n",
       " 'svc': array([[3.21488694e-06, 1.60253796e-06, 9.99995183e-01],\n",
       "        [9.13873738e-01, 7.98106989e-04, 8.53281555e-02],\n",
       "        [9.54894342e-01, 6.01869238e-03, 3.90869658e-02],\n",
       "        ...,\n",
       "        [8.90517662e-06, 9.98498491e-01, 1.49260423e-03],\n",
       "        [6.07244766e-06, 9.98761599e-01, 1.23232883e-03],\n",
       "        [1.62057543e-02, 9.63756728e-01, 2.00375180e-02]]),\n",
       " 'decision': array([[0., 0., 1.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        ...,\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.]]),\n",
       " 'extra': array([[0., 0., 1.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        ...,\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.]])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_probas = models.predict_proba(X_test)\n",
    "pred_probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.evaluate(test_X=X_test, test_Y=y_test, idx_label_dic=None, class_report=\"classf_report.csv\", con_mat=\"confusion_matrix.csv\", pred_proba=\"predictions_proba.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
